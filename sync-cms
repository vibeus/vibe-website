#!/usr/bin/env python3
import argparse
import json
import os
import re
import requests
import subprocess
import sys
import time
from PIL import Image
from colorama import Fore, Style
from io import BytesIO

MAX_PNG_SIZE = 3 * 1024 * 1024

if sys.version_info.major < 3 or sys.version_info.minor < 7:
    print("Python 3.7+ is required.")
    sys.exit(1)

try:
    global git_root
    git_root = subprocess.check_output(
        ["git", "rev-parse", "--show-toplevel"], text=True
    ).strip()
    print(Style.DIM + "Using root directory: {}".format(git_root) + Style.RESET_ALL)
except:
    print("Git not found or not in a Git repository.")
    sys.exit(1)

access_token = os.environ.get("VIBE_CMS_TOKEN", "")


def get_doc(doc_id):
    retry_count = 3

    while True:
        arg = {"doc_id": doc_id, "export_format": {".tag": "markdown"}}
        resp = requests.post(
            "https://api.dropboxapi.com/2/paper/docs/download",
            headers={
                "authorization": "Bearer {}".format(access_token),
                "Dropbox-API-Arg": json.dumps(arg),
            },
        )

        if resp.status_code != 200:
            if retry_count <= 0:
                raise RuntimeError("Failed to download doc id: {}".format(doc_id))
            else:
                retry_count -= 1
                print(
                    Style.DIM
                    + "Download {} failed with code {}. Retry in 10s...".format(
                        doc_id, resp.status_code
                    )
                    + Style.RESET_ALL
                )
                time.sleep(10)
                continue

        return resp.content.decode("utf-8")


def parse_doc_list(content):
    for line in content.splitlines():
        m = re.search("\(https://paper\.dropbox\.com/doc/([^/]+?)-(\w+)\)", line)
        if m:
            # [doc_id, doc_name]
            yield [m.group(2), m.group(1)]


def get_line_value(content, pattern, group_id=1):
    for line in content.splitlines():
        m = re.search(pattern, line)
        if m:
            return m.group(group_id)


def extract_front_matter(content):
    inFM = False
    inBody = False
    fm = []
    body = []

    for line in content.splitlines():
        if inBody:
            body.append(line)
        elif line.strip() == "---":
            if inFM:
                inFM = False
                inBody = True
            else:
                inFM = True
        elif inFM and not line.strip().startswith("slug:"):
            fm.append(line[4:])

    return "\n".join(fm), "\n".join(body)


def get_image_file_ext(content_type):
    if content_type == "image/png":
        return ".png"
    elif content_type == "image/jpeg" or content_type == "image/jpg":
        return ".jpg"
    else:
        raise RuntimeError("Unsupported image content type: {}".format(content_type))


# Download images discovered in content, and replace with hugo shortcode local names.
def download_images(content, directory, allow_large_image):
    lines = []
    images = {}
    index = 0
    has_cover = False
    has_content = False

    for line in content.splitlines():
        any_match = False
        for match in re.finditer("!\[(.*?)\]\((.+?)\)", line):
            any_match = True
            if match:
                caption = match.group(1)
                url = match.group(2)
                if not url in images:
                    resp = requests.get(url)
                    ext = get_image_file_ext(resp.headers["Content-Type"])
                    basename = "image-{}".format(index) if has_content else "cover"
                    if basename == "cover":
                        with Image.open(BytesIO(resp.content)) as img:
                            width, height = img.size
                            if width / height > 1.95:
                                basename = "cover-fullwidth"

                    if ext == ".png" and len(resp.content) > MAX_PNG_SIZE:
                        message = (
                            "{}: Image [{}] size {} bytes exceeds limit of {}.".format(
                                os.path.basename(directory),
                                basename + ext,
                                len(resp.content),
                                MAX_PNG_SIZE,
                            )
                        )

                        if allow_large_image:
                            print(Fore.RED + message + Style.RESET_ALL)
                        else:
                            raise RuntimeError(message)

                    # only accept one cover image per blog post.
                    if basename == "cover" and has_cover:
                        print(
                            Fore.YELLOW
                            + "  WARNING: ignored additional cover image: {}".format(
                                url
                            )
                            + Style.RESET_ALL
                        )
                        line = ""
                        continue

                    fn = basename + ext
                    images[url] = fn
                    index += 1

                    with open(os.path.join(directory, fn), "wb") as f:
                        f.write(resp.content)

                    print(
                        Style.DIM
                        + "  Downloaded image {} as {}".format(
                            url, os.path.join(directory, fn)
                        )
                        + Style.RESET_ALL
                    )

                # do not put cover-fullwidth into md file
                if basename == "cover-fullwidth":
                    line = ""
                else:
                    filename = images[url]
                    line = line.replace(
                        match.group(0),
                        '{{{{< common/srcset "{}" "{}" >}}}}'.format(filename, caption),
                    )

                    if basename == "cover":
                        has_cover = True

                        # new blog style does not need cover in md file
                        line = ""

        if not any_match and line.strip():
            has_content = True

        lines.append(line)

    return "\n".join(lines)


# capture youtube video links and convert into thumbnail urls.
def process_video_links(content):
    lines = []
    video_ids = []

    for line in content.splitlines():
        for match in re.finditer(
            "https://www\\.youtube.com/watch\\?v=([a-zA-Z0-9_-]+)", line
        ):
            if match:
                video_id = match.group(1)
                video_ids.append(video_id)
                print(
                    Style.DIM
                    + "  Detected Youtube video {}".format(video_id)
                    + Style.RESET_ALL
                )
                line = line.replace(
                    match.group(0),
                    "![](https://i3.ytimg.com/vi/{}/maxresdefault.jpg)".format(
                        video_id
                    ),
                )

        lines.append(line)

    return "\n".join(lines), video_ids


def fix_link_format(content):
    lines = []
    for line in content.splitlines():
        # [***blah blah***](https://address) => [blah blah](https://address)
        # [******](https://address) => delete
        for match in re.finditer("""\[\*\*\*([^*\[\]]*)\*\*\*\](\([^()]+\))""", line):
            if match:
                if len(match.group(1)) > 0:
                    line = line.replace(
                        match.group(0), "[{}]{}".format(match.group(1), match.group(2))
                    )
                else:
                    line = line.replace(match.group(0), "")

        lines.append(line)

    return "\n".join(lines)


def process_doc(doc_id, is_dev, allow_large_image, cms_type):
    content = get_doc(doc_id)

    title = get_line_value(content, "^# (.+)$")

    # It seems to be a common mistake to have bold style in title which is indistinguishable in Dropbox Paper,
    # but will cause rendering issue in CMS. So we strip it here.
    # Alternative solution is to strip them in CMS's layout script. However, we have some custom styling (~ to newline)
    # so do it here to avoid complexity.
    title = re.sub(r"\*\*([^*]+)\*\*", r"\1", title)

    slug = get_line_value(content, "^    slug: (.+)$").lower()
    if not slug:
        print(
            Fore.YELLOW
            + "Ignored doc {} because it does not have slug defined.".format(doc_id)
            + Style.RESET_ALL
        )
        return

    slug = slug.replace("'", "").replace(" ", "-")
    fm, body = extract_front_matter(content)

    if is_dev:
        slug = "dev-" + slug

    subfolder = "blog"
    if cms_type == "video":
        subfolder = "video-tutorial"

    md_path = os.path.join(git_root, "content", subfolder, slug, "index.md")
    os.makedirs(os.path.dirname(md_path), exist_ok=True)

    video_ids = []
    if cms_type == "video":
        body, video_ids = process_video_links(body)
    body = fix_link_format(body)
    body = download_images(body, os.path.dirname(md_path), allow_large_image)

    with open(md_path, "w") as f:
        f.write("---\n")
        f.write('title: "{}"\n'.format(title.replace('"', '\\"')))
        f.write("slug: {}\n".format(slug))
        f.write(fm)
        if cms_type == "video" and len(video_ids) > 0:
            f.write("\nvideoId: {}".format(video_ids[0]))
            f.write(
                "\nallowIndex: false"
            )  # for now simply redirect to youtube so hide single page.
            f.write(
                "\nno_sitemap: true"
            )  # for now simply redirect to youtube so hide single page.
        if is_dev:
            f.write(
                "\nexpiryDate: 2018-01-01 # This makes post only show in dev environment\n"
            )
        f.write("\n---\n")

        f.write(body)
        if not body.endswith("\n"):
            f.write("\n")


def main():
    global access_token

    parser = argparse.ArgumentParser(
        description="Sync blog posts or video tutorials from Dropbox Paper."
    )
    parser.add_argument("--manifest", help="The manifest doc.")
    parser.add_argument("--token", help="Dropbox access token")
    parser.add_argument("--dev", action="store_true", help="download as dev post")
    parser.add_argument(
        "--filter", help="Only process given doc id, or name contains given value."
    )
    parser.add_argument(
        "--allow-large-image",
        dest="allow_large_image",
        action="store_true",
        help="Allow large image file.",
    )
    parser.add_argument(
        "cms_type",
        choices=["blog", "video"],
        default="blog",
        help="which content to sync.",
    )
    args = parser.parse_args()

    if args.token:
        access_token = args.token

    if not access_token:
        print("VIBE_CMS_TOKEN is required")
        sys.exit(1)

    manifest_id = args.manifest
    if not manifest_id:
        if args.cms_type == "blog":
            manifest_id = "XWvIYMXhbzTYauPlxCd7j"
        elif args.cms_type == "video":
            manifest_id = "YL42N69s4TbdFo30n1hUd"
        else:
            print("Cannot guess manifest id.")

    manifest_content = get_doc(manifest_id)
    count = 0
    for doc in parse_doc_list(manifest_content):
        doc_id = doc[0]
        doc_name = doc[1]
        if args.filter and doc_id != args.filter and args.filter not in doc_name:
            print(
                Style.DIM
                + "Ignore doc {}: {} due to --filter {}".format(
                    doc_id, doc_name, args.filter
                )
                + Style.RESET_ALL
            )
            continue
        print("Processing doc {}: {}".format(doc_id, doc_name))
        process_doc(doc_id, args.dev, args.allow_large_image, args.cms_type)
        count += 1

    print(
        Fore.GREEN
        + "Successfully processed {} documents.".format(count)
        + Style.RESET_ALL
    )


if __name__ == "__main__":
    main()
