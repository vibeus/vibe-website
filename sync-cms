#!/usr/bin/env python3
import argparse
import json
import os
import re
import requests
import subprocess
import sys
from PIL import Image
from colorama import Fore, Style
from io import BytesIO

MAX_PNG_SIZE = 3 * 1024 * 1024

if sys.version_info.major < 3 or sys.version_info.minor < 7:
    print("Python 3.7+ is required.")
    sys.exit(1)

try:
    global git_root
    git_root = subprocess.check_output(
        ["git", "rev-parse", "--show-toplevel"], text=True
    ).strip()
    print(Style.DIM + "Using root directory: {}".format(git_root) + Style.RESET_ALL)
except:
    print("Git not found or not in a Git repository.")
    sys.exit(1)

access_token = os.environ.get("VIBE_CMS_TOKEN", "")


def get_doc(doc_id):
    arg = {"doc_id": doc_id, "export_format": {".tag": "markdown"}}
    resp = requests.post(
        "https://api.dropboxapi.com/2/paper/docs/download",
        headers={
            "authorization": "Bearer {}".format(access_token),
            "Dropbox-API-Arg": json.dumps(arg),
        },
    )

    if resp.status_code != 200:
        raise RuntimeError("Failed to download doc id: {}".format(doc_id))

    return resp.content.decode("utf-8")


def parse_doc_list(content):
    for line in content.splitlines():
        m = re.search("\(https://paper\.dropbox\.com/doc/([^/]+?)-(\w+)\)", line)
        if m:
            # [doc_id, doc_name]
            yield [m.group(2), m.group(1)]


def get_line_value(content, pattern, group_id=1):
    for line in content.splitlines():
        m = re.search(pattern, line)
        if m:
            return m.group(group_id)


def extract_front_matter(content):
    inFM = False
    inBody = False
    fm = []
    body = []

    for line in content.splitlines():
        if inBody:
            body.append(line)
        elif line.strip() == "---":
            if inFM:
                inFM = False
                inBody = True
            else:
                inFM = True
        elif inFM and not line.strip().startswith("slug:"):
            fm.append(line[4:])

    return "\n".join(fm), "\n".join(body)


def get_image_file_ext(content_type):
    if content_type == "image/png":
        return ".png"
    elif content_type == "image/jpeg" or content_type == "image/jpg":
        return ".jpg"
    else:
        raise RuntimeError("Unsupported image content type: {}".format(content_type))


# Download images discovered in content, and replace with hugo shortcode local names.
def download_images(content, directory, allow_large_image):
    lines = []
    images = {}
    index = 0
    has_cover = False
    has_content = False

    for line in content.splitlines():
        any_match = False
        for match in re.finditer("!\[(.*?)\]\((.+?)\)", line):
            any_match = True
            if match:
                caption = match.group(1)
                url = match.group(2)
                if not url in images:
                    resp = requests.get(url)
                    ext = get_image_file_ext(resp.headers["Content-Type"])
                    basename = "image-{}".format(index) if has_content else "cover"
                    if basename == "cover":
                        with Image.open(BytesIO(resp.content)) as img:
                            width, height = img.size
                            if width / height > 1.95:
                                basename = "cover-fullwidth"

                    if ext == ".png" and len(resp.content) > MAX_PNG_SIZE:
                        message = "{}: Image [{}] size {} bytes exceeds limit of {}.".format(
                            os.path.basename(directory),
                            basename + ext,
                            len(resp.content),
                            MAX_PNG_SIZE,
                        )

                        if allow_large_image:
                            print(Fore.RED + message + Style.RESET_ALL)
                        else:
                            raise RuntimeError(message)

                    # only accept one cover image per blog post.
                    if basename == "cover" and has_cover:
                        print(
                            Fore.YELLOW
                            + "  WARNING: ignored additional cover image: {}".format(
                                url
                            )
                            + Style.RESET_ALL
                        )
                        line = ""
                        continue

                    fn = basename + ext
                    images[url] = fn
                    index += 1

                    with open(os.path.join(directory, fn), "wb") as f:
                        f.write(resp.content)

                    print(
                        Style.DIM
                        + "  Downloaded image {} as {}".format(
                            url, os.path.join(directory, fn)
                        )
                        + Style.RESET_ALL
                    )

                # do not put cover-fullwidth into md file
                if basename == "cover-fullwidth":
                    line = ""
                else:
                    filename = images[url]
                    line = line.replace(
                        match.group(0),
                        '{{{{< common/srcset "{}" "{}" >}}}}'.format(filename, caption),
                    )

                    if basename == "cover":
                        has_cover = True

                        # new blog style does not need cover in md file
                        line = ""

        if not any_match and line.strip():
            has_content = True

        lines.append(line)

    return "\n".join(lines)


# capture youtube video links and convert into thumbnail urls.
def process_video_links(content):
    lines = []
    video_ids = []

    for line in content.splitlines():
        for match in re.finditer(
            "https://www\\.youtube.com/watch\\?v=([a-zA-Z0-9_-]+)", line
        ):
            if match:
                video_id = match.group(1)
                video_ids.append(video_id)
                print(
                    Style.DIM
                    + "  Detected Youtube video {}".format(video_id)
                    + Style.RESET_ALL
                )
                line = line.replace(
                    match.group(0),
                    "![](https://i3.ytimg.com/vi/{}/maxresdefault.jpg)".format(
                        video_id
                    ),
                )

        lines.append(line)

    return "\n".join(lines), video_ids


def process_doc(doc_id, is_dev, allow_large_image, cms_type):
    content = get_doc(doc_id)

    title = get_line_value(content, "^# (.+)$")

    # It seems to be a common mistake to have bold style in title which is indistinguishable in Dropbox Paper,
    # but will cause rendering issue in CMS. So we strip it here.
    # Alternative solution is to strip them in CMS's layout script. However, we have some custom styling (~ to newline)
    # so do it here to avoid complexity.
    title = re.sub(r"\*\*([^*]+)\*\*", r"\1", title)

    slug = get_line_value(content, "^    slug: (.+)$").lower()
    if not slug:
        print(
            Fore.YELLOW
            + "Ignored doc {} because it does not have slug defined.".format(doc_id)
            + Style.RESET_ALL
        )
        return

    slug = slug.replace("'", "").replace(" ", "-")
    fm, body = extract_front_matter(content)

    if is_dev:
        slug = "dev-" + slug

    subfolder = "blog"
    if cms_type == "video":
        subfolder = "video-tutorial"

    md_path = os.path.join(git_root, "content", subfolder, slug, "index.md")
    os.makedirs(os.path.dirname(md_path), exist_ok=True)

    body, video_ids = process_video_links(body)
    body = download_images(body, os.path.dirname(md_path), allow_large_image)

    with open(md_path, "w") as f:
        f.write("---\n")
        f.write('title: "{}"\n'.format(title.replace('"', '\\"')))
        f.write("slug: {}\n".format(slug))
        f.write(fm)
        if cms_type == "video" and len(video_ids) > 0:
            f.write("\nvideoId: {}".format(video_ids[0]))
            f.write(
                "\nallowIndex: false"
            )  # for now simply redirect to youtube so hide single page.
            f.write(
                "\nno_sitemap: true"
            )  # for now simply redirect to youtube so hide single page.
        if is_dev:
            f.write(
                "\nexpiryDate: 2018-01-01 # This makes post only show in dev environment\n"
            )
        f.write("\n---\n")

        f.write(body)
        if not body.endswith("\n"):
            f.write("\n")


def main():
    global access_token

    parser = argparse.ArgumentParser(
        description="Sync blog posts or video tutorials from Dropbox Paper."
    )
    parser.add_argument("--manifest", help="The manifest doc.")
    parser.add_argument("--token", help="Dropbox access token")
    parser.add_argument("--dev", action="store_true", help="download as dev post")
    parser.add_argument(
        "--filter", help="Only process given doc id, or name contains given value."
    )
    parser.add_argument(
        "--allow-large-image",
        dest="allow_large_image",
        action="store_true",
        help="Allow large image file.",
    )
    parser.add_argument(
        "cms_type",
        choices=["blog", "video"],
        default="blog",
        help="which content to sync.",
    )
    args = parser.parse_args()

    if args.token:
        access_token = args.token

    if not access_token:
        print("VIBE_CMS_TOKEN is required")
        sys.exit(1)

    manifest_id = args.manifest
    if not manifest_id:
        if args.cms_type == "blog":
            manifest_id = "XWvIYMXhbzTYauPlxCd7j"
        elif args.cms_type == "video":
            manifest_id = "YL42N69s4TbdFo30n1hUd"
        else:
            print("Cannot guess manifest id.")

    manifest_content = get_doc(manifest_id)
    count = 0
    for doc in parse_doc_list(manifest_content):
        doc_id = doc[0]
        doc_name = doc[1]
        if args.filter and doc_id != args.filter and args.filter not in doc_name:
            print(
                Style.DIM
                + "Ignore doc {}: {} due to --filter {}".format(
                    doc_id, doc_name, args.filter
                )
                + Style.RESET_ALL
            )
            continue
        print("Processing doc {}: {}".format(doc_id, doc_name))
        process_doc(doc_id, args.dev, args.allow_large_image, args.cms_type)
        count += 1

    print(
        Fore.GREEN
        + "Successfully processed {} documents.".format(count)
        + Style.RESET_ALL
    )


if __name__ == "__main__":
    main()
